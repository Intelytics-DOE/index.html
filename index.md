---
layout: default
title: "Home"
---

# Optimizing Performance in High-Performance Computing Environments

The Intelytics project addresses the challenges posed by increasingly **heterogeneous High-Performance Computing (HPC)** environments. Our research aims to develop data-driven models and machine learning (ML)-based solutions to improve the performance and efficiency of applications running on supercomputers.

We are focused on **automating decision-making** in these complex environments by combining **AI/ML techniques** with HPC expertise. Our work spans several areas including performance characterization, bottleneck detection, reproducibility, and the creation of scalable, efficient models that support real-time decision-making.

---

## Our Research Focus

### 1. **Data Representation for Performance Modeling**  
We are developing new methods to represent multi-modal performance data using graph-based techniques, which improve **real-time decision-making** by accurately clustering performance samples. This innovative approach enhances the ability to quickly classify new data, yielding performance models that are up to 61% more accurate than state-of-the-art methods.

- **Impact**: Enables time- and data-efficient decision-making, with applications in disaster response, manufacturing, and autonomous vehicles.

### 2. **AI/ML-Based Performance Models**  
Our research also involves designing AI/ML methodologies that can use these advanced data representations to optimize performance across diverse HPC environments. We aim to develop models that balance performance, power efficiency, system utilization, and variability.

- **Impact**: Successful technology transfers, including integration with Lawrence Berkeley Lab's GPTune auto-tuner and AMDâ€™s OmniPerf.

### 3. **Cross-Platform Performance Modeling**  
To address the challenges of predicting performance on new architectures, we combine **few-shot learning** with **generative AI** techniques. This allows us to synthesize performance models with minimal data collection, which is essential given the rapid development of new supercomputing architectures.

- **Impact**: Enables faster scientific discovery and supercomputer evaluation by reducing the time needed to collect performance data.

### 4. **Reproducibility and FAIR Data in HPC**  
Our novel approaches also focus on making HPC performance data reproducible and **FAIR (Findable, Accessible, Interoperable, Reusable)**. By improving metadata collection practices and applying graph-based ML models, we aim to make performance results more reliable across different environments.

- **Impact**: Contributes to future reproducibility in science and HPC research.

---

## Recent Publications

Below is a list of our recent publications:

1. **Signal Processing Based Method for Real-Time Anomaly Detection in High-Performance Computing**  
   *2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)*, pp. 233-240.  
   [DOI: Available soon]

2. **Novel Representation Learning Technique using Graphs for Performance Analytics**  
   *2023 International Conference on Machine Learning and Applications (ICMLA)*, pp. 1311-1318.  
   [DOI: Available soon]

3. **Toward Efficient Deep Learning Inference: On-Node Heterogeneous Scheduling in Edge-Cloud Infrastructure**  
   *2024 IEEE Cloud Summit*, pp. 73-78.  
   [DOI: Available soon]

4. **Data-Driven Analysis to Understand GPU Hardware Resource Usage of Optimizations**  
   *arXiv preprint arXiv:2408.10143*, 2024.  
   [DOI: Available soon]

5. **PERFGEN: A Synthesis and Evaluation Framework for Performance Data using Generative AI**  
   *2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)*, pp. 188-197.  
   [DOI: Available soon]

6. **On The Role of Prompt Construction In Enhancing Efficacy and Efficiency of LLM-Based Tabular Data Generation**  
   *arXiv preprint arXiv:2409.03946*, 2024.  
   [DOI: Available soon]

---

## Collaborate With Us

Interested in collaborating or learning more about our work? Feel free to [contact us](mailto:contact@xyzresearch.org). We'd love to hear from you!

---

